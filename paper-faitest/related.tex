\section{Related Work}
\label{sect:related}
Transparency and understanding of the implications of various policies applied
to data by modern data-driven web applications is drawing increasing attention
in our days. Yet, there is no well-established methodology for asserting
non-discriminatory treatment of online users of pricing engines,
recommendation engines, and even hiring web sites. The notion of
(non-)discriminatory treatment of populations had already been perceived two decades
ago by the authors of~\cite{EmploymentDisc}. In this work regression is being
used to test for salary discrimination among males and females, and the concept
of fairness against employment discrimination is introduced. Afterwards,
there has been a large body of work that revisited the concept of fairness and
attempted to assert against discriminatory treatment of individuals:
of~\cite{HiringDiscrimination,FairnessAwareness,FairnessRegularization,
FairRepresentation,DisparateImpact}.

The authors of~\cite{HiringDiscrimination} investigate the impact of
information shared in social networks on the hiring of individuals, and claim
evidences of hiring discrimination based on this information. The authors
of~\cite{FairnessAwareness} study the fairness in classification of users and
assert that certain individuals are not discriminated, while some utility
of the classifier is maintained. Moreover, Zemel et al.
~\cite{FairRepresentation} formalize fairness as an optimization problem and
present a technique to achieve both individual and group fairness. Also, the
authors of~\cite{DisparateImpact} examine algorithmic biases under the spectrum
of disparate impact, and present methods for making data unbiased, i.e.,
removing disparate impact. In~\cite{FairnessRegularization} a regularization
technique is presented to safeguard against causes of unfairness in machine
learning techniques and to eliminate biases in determinations due to indirect
dependences on sensitive information, such as gender and religion. \sysname
differs from the previous works, since we actually implement a system that
helps assert fairness amongst users.

Closer to our work, pricing and hiring discrimination in online applications is
investigated in~\cite{PriceDiscrimination,SearchDiscrimination,XRay}.
In~\cite{PriceDiscrimination}, the authors present a measurement study of the
ways in which e-commerce web sites discriminate based on users' browsing
profile and optimize prices. In~\cite{SearchDiscrimination},  the authors
present a study that demonstrates the existence of both price and search
discrimination on the internet. Finally, in~\cite{HiringDiscrimination}, the
authors implement a system to increase transparency in the for the Web. They
implement a tool which helps uncover which data, in an online account,
is used to target which outputs. Our approach differs from the above works in that
it is -- to the best of our knowledge -- the first system that helps assert
non-discriminatory treatment of users of web application. We design \sysname
as a service that can be used -- without fundamental limitations -- to
uncover {\em privacy bugs}  in any data-driven web application.
