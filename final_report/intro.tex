
\section{Introduction}

%general paragraph to set the ground about data-driven world and apps
Modern web applications are increasingly data-driven and assist users
with their every-day tasks, ranging from browsing social networks to
issuing bank transactions. Users are accessing these applications from
various personal devices such as smartphones, tablets, and desktop PCs,
and always expect a highly personalized experience. Therefore, modern
applications are now metamorphosing the internet from an unbiased, impersonal
service into a highly personalized service that dynamically reforms to match
each individual's preferences. This personalized versioning of the internet
is based on the collection and processing of users' data that aid profiling
of individuals and inferring matching preferences.

%paragraph to introduce the lack of transparency on data-use
Although there is a phenomenal evolution in the techniques and tools used to
process collected data and infer users' preferences, there is a stagnation
in the development of tools to increase transparency and accountability of
this data. Yet, all the more,  highly sensitive personal information is being
used from applications to enhance user experience and help create efficient
policies for online advertising, pricing, and hiring.
Developers notoriously miss tools to evaluate whether policies are
enforced correctly across collected data and whether their algorithms are
creating objectionable biases within user populations or not. Clearly,
the unpredictable ways in which data is being used, carry the danger of
unintentional data misuse, such as algorithmic discrimination of seemingly
unrelated users.

%Give a concrete motivating example
An indicative motivating example of data misuse is the ``Staples Inc.''
different treatment case, reported by the Wall Street Journal in 2012
~\cite{Staples}. In this case, an arguably reasonable algorithmic decision
to customize online prices based on user proximity to competitor
brick-and-mortar stores effectively led to objectionable bias:
Areas that tended to see discounted prices had a higher income than areas
that tended to see higher prices. Other examples of differential treatment in
web applications – intentional or unintentional – have been identified in a
variety of other contexts, including
advertising~\cite{Sweeney:AdDiscrimination},
pricing~\cite{Hannak:PriceDiscrimination}, and
hiring~\cite{acquisiti:HiringDiscrimination}. This kind of indirect --and likely
unintended-- effects are challenging to identify, and with the ubiquitous use
of sensitive information collected by web applications, the risk for these
dangers --or, privacy bugs-- is only increasing.

%Our approach
In this paper we present the theoretical foundation to formalize the notion of
discriminatory treatment of users in modern web applications. Then, we build
\sysname, a tool to increase developers’ visibility into the implications of
various data-use policies by reporting discriminatory treatment --or,
privacy bugs. Our theoretical foundation for identifying discriminatory
treatment of users examines the correlation between a set of outputs (shown to
users) and a set of user attributes. More precisely, user attributes are split
into two categories: (a) a set of protected user attributes such as race or
sexual orientation --which application should not use to implement their
policies and produce outputs-- and (b) a set of input attributes which
applications is legitimate to use to produce outputs. Based on this rule,
\sysname report's as privacy bugs any strong correlations between protected
user attributes and outputs shown to users.

%One paragraph to describe the system we built and how we evaluated it
We built \sysname and provide it as a service with a REpresentational
State Transfer (REST) Application Program Interface (API). Clients of the 
\sysname service --let them be application developers or external auditors,
e.g., the Federal Trade Commission (FTC)-- use its REST API to register users
and the corresponding outputs. Based on a set of registered users and the
corresponding outputs, \sysname then creates bug-reports and publishes them
into its web interface. These reports indicate any strong correlations between
(protected) user attributes and outputs. In Section~\ref{sect:fairtest} we
present in detail the architecture of \sysname's implementation and its API.
In order to evaluate our \sysname prototype, we used a set of synthetic users
that match the demographics of US population, simulate ``Staple Inc.'' pricing
policy, and use \sysname to generate bug-reports. Our results included
bug-reports that identify the discriminatory behavior of ``Staple  Inc.''
pricing policy. In Section~\ref{sect:evaluation} we detail more on our
experimental methodology and on the results of our evaluation.

Overall, this paper includes three major contributions:
\begin{itemize}
  \item The theoretical background necessary to formulate and evaluate the
    presence of discriminatory treatment of users of modern data-driven web
    applications.
  \item The design and implementation of \sysname, a service for identifying
    and reporting discriminatory treatment of users of modern data-driven
    applications.
  \item The evaluation of \sysname in the ``Staples Inc.'' pricing engine, a
    well know case of discriminatory treatment of users.
\end{itemize}

The rest of this paper is organized as follows. Section~\ref{sect:motivation}
present our theoretical foundations along with a set of motivating examples.
Section~\ref{sect:fairtest} gives an overview on our \sysname implementations
and its API. Section~\ref{sect:evaluation} presents results of the evaluation
of our \sysname prototype. Section~\ref{sect:related} describes related work,
and finally, section~\ref{sect:conclusion} includes our concluding remarks and
directions for future work.
