
\section{Introduction}

%general paragraph to set the ground about data-driven world and apps
Modern web applications are increasingly data driven and assist users
with their every-day tasks, ranging from browsing social networks to
issuing bank transactions. Users are accessing these applications from
various personal devices such as smartphones, tablets, and desktop PCs,
and always expect a highly personalized experience. Therefore, modern
applications are now metamorphosing the internet from an unbiased, impersonal
service into a highly personalized service that dynamically reforms to match
each individual's preferences. This personalized versioning of the internet
is based on the collection and processing of users' data that aid profiling
of individuals and infering matching preferences.

%paragraph to introduce the lack of transparency on data-use
Although there is a phenomenal evolution in the techniques and tools used to
process collected data and infer users' prefereces, there is a stagnation
in the development of tools to increase transparency and acountability of
this data. Yet, all the more,  highly sensitive personal information is being
used from applications to enhance user experience and help create efficient
policies (XXX Policies for what?).
Developers notoriously miss tools to evaluate whether policies are
enforced correctly across collected data and whether their algorithms are
creating objectionable biases within user populations or not. Clearly,
these unpredictable ways in which data is being used carry the danger of
unintentional data misuse, such as algorithmic discrimination of seemingly
unrelated users.

%Give a conctrete motivating example
An indicative motivating example of data misuse is the ``Staples Inc.''
different treatment case, reported by the Wall Street Journal in 2012
~\cite{Staples}. In this case, an arguably reasonable algorithmic decision
to customize online prices based on user proximity to competitor
brick-and-mortar stores effectively led to objectionable bias:
Areas that tended to see discounted prices had a higher income than areas
that tended to see higher prices. Other examples of differential treatment in
web applications – intentional or unintentional – have been identified in a
variety of other contexts, including advertising~\cite{}, pricing~\cite{},
and hiring~\cite{}. This kind of indirect --and likely unintended--
effects are challenging to identify, and with the ubiquituous use of sensitive
information collected by web applications, the risk for these dangers is only
increasing. We call such effects privacy bugs and build FaiTest,
a tool to increase developers’ visibility into the implications of various
policies applied to collected data.


%One paragraph to introduce our approach for fairness and our idea of reporting privacy bugs.
%One paragraph to describe the system we built to measure fairness.
%One paragraph describing how we evaluate our system.
%One paragraph to describe 3 major contributions of our work
